\documentclass[english,letterpaper,12pt]{article}
%\usepackage[margin=1in]{geometry}

% Encoding, fonts, and language (fold)
\usepackage[utf8]{inputenc}
\DeclareUnicodeCharacter{2212}{\textminus}
\usepackage[T1]{fontenc}
\usepackage[pdftex,
            pdfauthor={Max Veit},
            pdftitle={Simulation of Genetic Regulatory Networks},
            pdfkeywords={stochastic simulation genetic regulatory networks epigenetics}]{hyperref}
\usepackage{fouriernc}
\usepackage{tgschola}
\usepackage{babel}
% (end)

% Mathematics and symbols (fold)
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{xfrac}
\usepackage{gensymb}
\usepackage{textcomp}
\usepackage{mathtools}
\usepackage{siunitx}
% (end)

% Figures (fold)
\usepackage{graphicx}
\usepackage{float}
\usepackage{subcaption}
%\usepackage[font=scriptsize, it]{caption}
\usepackage{placeins}
% (end)

% Gnuplot vector images (fold)
\usepackage{pgf}
\usepackage{pgfplots}
\usepackage{tikz}
\usepackage{gnuplot-lua-tikz}
% (end)

% Source code listings (fold)
\usepackage{listings}
\usepackage{algorithmic}
% (end)

% Text-level formatting (fold)
\usepackage{color}
\usepackage{setspace}
\usepackage{multicol}
\frenchspacing
\usepackage[square,numbers]{natbib}
\sisetup{per-mode=symbol-or-fraction}
%\numberwithin{equation}{section}
% (end)

% Convenience / typographical consistency
\newcommand{\defkeywd}[1]{\textbf{#1}}
\usepackage[enable]{easy-todo}
% Deprecated - don't play nice with latex-suite autocomplete
\newcommand{\figref}[1]{Figure~\ref{#1}}
\newcommand{\secref}[1]{Section~\ref{#1}}

% Custom math symbols, commands
\newcommand{\tenexp}[1]{\times10^{#1}}
\newcommand{\dee}{\;\mathrm{d}}
\let\oldvec\vec
\renewcommand{\vec}[1]{\ensuremath{\mathbf{#1}}}
\newcommand{\evec}[1]{\ensuremath{\vec{e}_{#1}}} % standard basis vector
\newcommand{\norm}[2]{\ensuremath{\|#1\|_{#2}}}
\newcommand{\bignorm}[2]{\ensuremath{\left\|#1\right\|_{#2}}}
\newcommand{\infnorm}[1]{\ensuremath{\|#1\|_\infty}}
\newcommand{\reals}{\ensuremath{\mathbb{R}}}
\DeclareMathOperator{\Prob}{P}
% Physics Domain-Specific
\newcommand{\kB}{\ensuremath{k_\mathrm{B}}}
% Document-specific
\newcommand{\delaytime}{\ensuremath{\tau}}

% Headers and Footers
\usepackage{fancyhdr}
\pagestyle{fancy}
\lhead{Max Veit\\University of Minnesota}
\rhead{Simulation of Genetic\\Regulatory Networks}
\chead[]{}
\cfoot{\thepage}
\setlength{\headheight}{27.7pt}

\begin{document}
\title{Stochastic Simulation of Genetic Regulatory Networks with Delayed Reactions}
\author{Max Veit}
\date{5 May 2014}

%TODO Format the title page according to UHP requirements (including acknowledgements, non-technical summary, etc.
\maketitle

% May not be necessary, but nice to have for now.
\tableofcontents

\begin{doublespacing}

\section{Introduction} % (fold)
\label{sec:introduction}

%TODO Background references look a little thin - maybe add some more from browsing around?
Recent research in biological physics~\cite{ecoli-decision} indicates that the behavior and internal workings of a living cell is much more rich and complex than the bare instructions coded into its DNA would suggest. For example, an individual section of DNA can be turned off when a repressor protein binds to the beginning of that section. Such mechanisms provide cells a way to change the expression of their DNA, i.e. to control which proteins are produced from their genes and in what amounts, an ability known as (genetic) transcriptional regulation. This ability allows genetically identical cells to adapt their behavior to different environments or to differentiate into different types of cells as in the development of a multicellular organism. Developing models for the selective expression of genes is key to understanding how cells perform their daily functions and respond to their enviroments.

%TODO Ref on biological circuitry would be helpful
Another interesting feature of transcriptional regulation is the presence of feedback. Real cells have many \todo{how many?} genes that can each individually be switched on or off. This allows genetic switches to interact in complex ways, forming a genetic regulator network. An example would be two regions of DNA that each code for proteins that suppress the other region, although much more complex feedback mechanisms are found in real cells as well as synthesized in laboratories. \todo{examples?} Such mechanisms have the potential to be harnessed as a form of biological circuitry - computation done with chemical reactions instead of electricity~\cite{bio-circuits}. Basic components, such as oscillators, have already been synthesized~\cite{synth-osc}. Biological circuitry promises to deliver a level of control over cells that would allow bacteria to be harnessed for producing chemicals or fulfilling other useful roles in the body. Advancement of this field, however, depends on a better understanding of genetic networks and their behavior.

Many efforts have been made to theoretically model genetic regulatory networks. \todo{refs? examples?} Strategies for modeling such networks must also account for the stochasticity resulting from the presence of thermal fluctuations coupled with the small size of cells. Experiments~\cite{ecoli-decision} show that this stochasticity has a major influence on the function of these networks.

One method for modeling genetic regulatory networks is a technique known as system size expansion. This analytical technique captures some of the stochastic character of real genetic regulatory networks, but has some limitations. \todo{which? where do results differ from real cells? Expand.}

The method explored in this work is to directly simulate the sequence of chemical reactions occurring in the cell using a Monte Carlo algorithm. The algorithm is known as the Gillespie stochastic simulation algorithm (SSA) and has seen use before in the context of genetic networks. \todo{refs?} The aim of this work is to extend the SSA to make it more practical for simulating real-world (natural or synthetic) genetic regulatory networks in order to analyze their behavior.

% section Introduction (end)

\section{Stochastic Chemical Kinetics} % (fold)
\label{sec:chemkin}

In order to study the behavior of genetic networks on a molecular level, \todo{right term?} they are usually modeled as chemical systems evolving under sets of coupled chemical reactions. The reactions represent actions such as the binding of repressors to DNA sites, protein production, and protein degradation. This representation allows genetic networks to be studied from the perspective of chemical kinetics, which seeks to understand the time evolution of the concentrations of the reactants in a system. In the case of genetic networks, the reactants are the proteins that drive the dynamics of the network. \todo{I don't like that wording -- need something better} The \defkeywd{state} of a chemical system refers to the set of concentrations of all the reactants -- in this case, all the proteins \todo{and mRNA?} -- involved in the system.

%TODO Conflates discreteness with stochasticity - is there a need to distinguish the two?
In theories, such as reaction-rate equations (RRE), where the continuum limit is used the concentration of every reactant is assumed to be a continuuous variable. This limit is only valid for large systems, that is, in systems where the smallest change possible in the concentration of any reactant $X$ (the difference caused by adding or removing one molecule of $X$) is negligibly small relative to its average concentration $\bar{x}$. In small systems, i.e. in systems where the above limit is violated, the concentration of the reactants must be treated as discrete and the RRE formalism no longer gives a good description of the chemical system.

%TODO Bit of a weak intro for stochastic chemkin - see if there's a more interesting way to bring it in
The theory of stochastic chemical kinetics explicitly treats the discreteness and stochasticity present in small systems. It avoids solving for a \emph{deterministic} trajectory describing how the reactants evolve in time, as the RRE method does. Instead, it attempts to find the \emph{probability} that the chemical system will be be in a given state at a given time. It does this by employing the fundamental assumption that the probability that a given reaction $R_j$ will occur within the system volume in the next infinitesimal time interval of length $\dee t$ depends only on the current state $\vec{x}$. This probability is written as $a_j(\vec{x}) \dee t$, where the function $a_j(\vec{x})$ is known as the \defkeywd{propensity function} \cite{gillespie-ssa}. In other words, the fundamental assumption of chemical kinetics is that the chemical system can be represented as a (continuous-time) Markov chain.

Using the above assumption, it is possible to derive a differential equation that describes the time evolution of the probability distribution of the system. This probability distribution is written $\Prob(\vec{x}, t | \vec{x}_0, t_0)$, which means ``the probability, given that the system started in the state $\vec{x}_0$ at time $t_0$, that the system will be in the state $\vec{x}$ at some later time $t$.'' The equation is called the chemical master equation, and in the form given in \cite{gillespie-ssa}, it reads:
\begin{equation}
    \frac{\partial}{\partial t} \Prob(\vec{x}, t | \vec{x}_0, t_0) = \sum_j \left( a_j (\vec{x} - \vec{s}_j) \Prob(\vec{x} - \vec{s}_j, t | \vec{x}_0, t_0) - a_j(\vec{x}) \Prob(\vec{x}, t | \vec{x}_0, t_0) \right)
    \label{eq:master-eqn}
\end{equation}
The sum runs over all the reaction pathways in the chemical system. The vector $\vec{s}_j$, known as the state-change vector of reaction $j$, indicates the effect of the reaction $j$ on the state of the chemical system: reaction $j$ takes the state instantaneously from $\vec{x}$ to $\vec{x} + \vec{s}_j$.

The above definition of propensity and the resulting Master equation rely on several simplifying assumptions about the system. The most severe of these is that the chemical system is assumed to be a homogeneous (well-stirred) ideal gas or dilute solution. \todo{may need reference that details assumptions, since Gillespie (2007) doesn't mention the ideal-gas part} While these assumptions begin to break down in living cells (see Section~\ref{sub:diffusion-crowded}), the utility and ease of implementation of algorithms to solve the chemical master equation have led to wide use of this theory in modeling the biochemistry of cells. \todo{refs - maybe a review article?}

\subsection{Delayed Reactions} % (fold)
\label{sub:delayed-reactions}

In order to reduce the computational cost and model complexity of applying the SSA to biological systems, an additional abstraction is adopted. Processes common in cell biology, such as DNA replication, protein production, and protein digestion, actually consist of sequences of thousands \todo{right number?} of individual chemical reactions like the binding of individual nucleotides to a developing RNA strand. It would be tedious and expensive to simulate each individual step of the process. More importantly, it would be extremely wasteful to do so if one is only interested in the outcome of the entire process. \todo{and the high-level dynamics of proteins - better wording}

One can avoid simulating each step of a complex biological process by modeling the entire process as a single reaction. For example, a protein-production reaction (which itself consists of many complex multi-step processes such as RNA transcription and protein folding) can be abstracted as a single reaction that produces a protein from nothing. However, this reaction cannot be said to occur instantaneously (as with simple chemical reactions), as the entire process it represents takes a certain time to complete. For example, the process of protein production \todo{gene expression?} takes about 5--10 minutes to complete in a typical cell. \todo{ref; what is a typical cell?}

To account for this time, one can associate a \defkeywd{delay} with the reaction to represent the time the underlying process needs to complete. In effect, the propensity function for the delayed reaction depends not on the current state, but on the history of the chemical system. More precisely, if reaction $j$ is delayed with a time $\delaytime_j$, its propensity function is written $a_j \left(\vec{x}(t - \delaytime_j) \right)$. For simplicity, $\delaytime_j$ is assumed to be a number. In general, however, the delay may be better characterized by a probability distribution.

Finally, introducing delayed reactions has an important consequence: Since delayed reactions depend on the history of chemical system, models incorporating them are non-Markovian. \todo{mention consequences later on?}

% subsection delayed-reactions (end)

% section chemkin (end)

\section{Methodology} % (fold)
\label{sec:methodology}

\subsection{Gillespie Stochastic Simulation Algorithm} % (fold)
\label{sub:gillespie-ssa}

One of the most well-known and widely used \todo{back up with refs} algorithms for simulating stochastic chemical systems is the stochastic simulation algorithm (SSA), which was popularized in 1976 by Daniel Gillespie although its origins date back further still \todo{references?}. As a Monte Carlo technique, it does not attempt to solve the Master Equation (Equation~\eqref{eq:master-eqn}) explicitly. Rather, the approach taken by the SSA is to generate a \defkeywd{trajectory}, which is one possible path $\vec{x}(t)$ the chemical system might take through the state space given some initial conditions $\vec{x}(t_0) = \vec{x}_0$. Unlike the deterministic trajectories found using RRE, these trajectories are generated probabilistically. The trajectories generated by the SSA can be seen as \emph{samples} of the underlying probability distribution $\Prob(\vec{x}, t | \vec{x}_0, t_0)$ that describes the chemical system. In principle, one can generate a very large number of samples (trajectories) in order to estimate a distribution that converges to the true one.

The SSA generates trajectories (with the initial conditions $\vec{x}(t_0) = \vec{x_0}$) by iterating the following steps \cite{gillespie-ssa}:
\todo{Make more mathematically precise}
\begin{enumerate}
    \item Compute the propensities $a_j(\vec{x}_n)$ for all reactions $j$ and their sum $a_\text{tot}(\vec{x}_n)$.
    \item Choose the next reaction time and type from the following probability distributions:
    \begin{itemize}
        \item Waiting time: $\Prob(t_w)\dee t_w = a_\text{tot}(\vec{x}_n) \exp(-a_\text{tot}(\vec{x}_n) t_w) \dee t_w$
        \item Reaction type: $\Prob(j) = a_j(\vec{x}_n) / a_\text{tot}(\vec{x}_n)$
    \end{itemize}
    \item Update the current state and time:
    \begin{itemize}
        \item $t_{n+1} = t_n + t_w$
        \item $\vec{x}_{n+1} = \vec{x}_n + \vec{s}_k$, where $\vec{s}_k$ is the state-change vector for the reaction chosen above
    \end{itemize}
\end{enumerate}
The iteration is continued typically until the time $t$ reaches (exceeds) a predefined stop time.

\todo{Detail on how to compute propensities}

\todo{Explain sampling from distributions, why these are chosen, what they represent, why do they make the trajectory follow the probability distribution}

% subsection gillespie-ssa (end)

\subsection{Extension to Non-Markovian Dynamics} % (fold)
\label{sub:non-markovian}

% Worth some discussion - Bratsun paper does it differently. Why do it my way?

% subsection non-markovian (end)

\subsection{Weighted-Ensemble Resampling} % (fold)
\label{sub:we-resampling-intro}

% subsection we-resampling-intro (end)

\subsection{Weighted Ensemble With Delays} % (fold)
\label{sub:we-delays}

% subsection we-delays (end)

\subsection{Verification Test Cases} % (fold)
\label{sub:verification}

% System for which analytical distribution is known

% Simple production-degradation system

% subsection verification (end)

% section Methodology (end)

\section{Model Reaction Systems} % (fold)
\label{sec:model-systems}
% TBD
% section model-systems (end)

\section{Results} % (fold)
\label{sec:results}
% TODO
% Some results available - talk about testing of WE, investigation of delayed-deg system
% section resultsResults (end)

\section{Conclusions and Future Work} % (fold)
\label{sec:conclusions}

% Future Work
\subsection{Modeling Crowded Environments} % (fold)
\label{sub:diffusion-crowded}

% subsection diffusion-crowded (end)

%     Crowded environments

% section conclusions (end)

\end{doublespacing}

\appendix

\bibliographystyle{apsrev}
\bibliography{citations.bib}

\end{document}

